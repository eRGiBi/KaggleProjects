{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# ISIC 2024 - Skin Cancer Detection with 3D-TBP\n",
    "\n",
    "Nicholas Kurtansky, Veronica Rotemberg, Maura Gillis, Kivanc Kose, Walter Reade, Ashley Chow. (2024). ISIC 2024 - Skin Cancer Detection with 3D-TBP. Kaggle. https://kaggle.com/competitions/isic-2024-challenge\n",
    "\n",
    "Currently heavily in development."
   ],
   "id": "b260f5b3bb829a73"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import os\n",
    "import os.path as path\n",
    "import gc\n",
    "import cv2\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# from torch.optim import lr_scheduler\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torch.cuda import amp\n",
    "# import torchvision\n",
    "# from torcheval.metrics.functional import binary_auroc\n",
    "\n",
    "# Tensorflow Imports\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# Utils\n",
    "# import joblib\n",
    "# from tqdm import tqdm\n",
    "# from collections import defaultdict\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold \n",
    "\n",
    "# For Image Models\n",
    "# import timm\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# For colored terminal text\n",
    "# from colorama import Fore, Back, Style\n",
    "# b_ = Fore.BLUE\n",
    "# sr_ = Style.RESET_ALL"
   ],
   "id": "2c1f0d5502d23b8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "env_cfg = {\n",
    "    \"seed\": 42,\n",
    "    # \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"verbosity\": '3',\n",
    "}"
   ],
   "id": "e2a6a118b6308d31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = env_cfg[\"verbosity\"]\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = env_cfg[\"verbosity\"]"
   ],
   "id": "3818397e011fe631",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "AUTOTUNE = tf.data.experimental.AUTOTUNE",
   "id": "fcc4d3503a76c82b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def set_seeds(seed=42):\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    \n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "    \n",
    "    # torch.manual_seed(seed)\n",
    "    # torch.cuda.manual_seed(seed)\n",
    "  \n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "    # torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "set_seeds()"
   ],
   "id": "e9800f6d5fd076a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# https://www.kaggle.com/code/motono0223/isic-pytorch-training-baseline-image-only#Training-Function\n",
    "\n",
    "ROOT_DIR = path.normpath(os.curdir + \"/data/\")\n",
    "TRAIN_DIR = f'{ROOT_DIR}/train-image/image/'\n",
    "\n",
    "def get_train_file_path(image_id):\n",
    "    return f\"{TRAIN_DIR}/{image_id}.jpg\""
   ],
   "id": "cbc6df94436a8e14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_images = sorted(glob.glob(f\"{TRAIN_DIR}/*.jpg\"))\n",
    "print(TRAIN_DIR)\n",
    "print(\"train_images>\", len(train_images))"
   ],
   "id": "659d62dcd698cf70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_images[:5]",
   "id": "34a0135258a81a2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(get_train_file_path(\"ISIC_0015864\"))\n",
    "img = cv2.imread(get_train_file_path(\"ISIC_0015864\"))\n",
    "\n",
    "plt.imshow(img)"
   ],
   "id": "702e6a1c7ceec21d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8f29376d58197683",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(f\"{ROOT_DIR}/train-metadata.csv\")\n",
    "\n",
    "print(\"        df.shape, # of positive cases, # of patients\")\n",
    "print(\"original\", df.shape, df.target.sum(), df[\"patient_id\"].unique().shape)\n",
    "\n",
    "df_positive = df[df[\"target\"] == 1].reset_index(drop=True)\n",
    "df_negative = df[df[\"target\"] == 0].reset_index(drop=True)\n",
    "\n",
    "# Potential imbalanced dataset\n",
    "# df = pd.concat([df_positive, df_negative.iloc[:df_positive.shape[0]*20, :]])  # positive:negative = 1:20\n",
    "# print(\"filtered\", df.shape, df.target.sum(), df[\"patient_id\"].unique().shape)\n",
    "\n",
    "df['file_path'] = df['isic_id'].apply(get_train_file_path)\n",
    "# df = df[ df[\"file_path\"].isin(train_images) ].reset_index(drop=True)\n",
    "df.head()"
   ],
   "id": "cbd67d11fb95b117",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Data exploration\n",
    "\n",
    "print(\"Number of unique patients: \", df[\"patient_id\"].nunique())"
   ],
   "id": "d6080202dd229c21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "name = ['Benign', 'Malignant']\n",
    "\n",
    "plt.figure(figsize = (5, 5))\n",
    "plt.pie(df.target.value_counts(normalize = True), autopct = '%1.1f%%', startangle = 90, wedgeprops = dict(width = 0.3), \n",
    "        labeldistance = 1.2, radius = 1)\n",
    "plt.title(f'Total Target Distribution', color = 'black', fontsize = 15)\n",
    "plt.legend(name,)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(df_negative.shape, df_positive.shape)"
   ],
   "id": "3b78a46923850c84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "missing_values_count = df.isnull().sum()\n",
    "print(sorted(missing_values_count, reverse=True))"
   ],
   "id": "a21d8c1738cc0ed5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "CONFIG = {\n",
    "    \"seed\": 42,\n",
    "    \"epochs\": 50,\n",
    "    \"img_size\": 384,\n",
    "    \"model_name\": \"\",\n",
    "    \"checkpoint_path\" : \"/ISIC2024_SkinCancerDetection/saved_models\",\n",
    "    \"train_batch_size\": 32,\n",
    "    \"valid_batch_size\": 64,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"scheduler\": 'CosineAnnealingLR',\n",
    "    \"min_lr\": 1e-6,\n",
    "    \"T_max\": 500,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"fold\" : 0,\n",
    "    \"n_fold\": 5,\n",
    "    \"n_accumulate\": 1,\n",
    "    # \"device\": nn.device(\"cuda:0\" if nn.cuda. else \"cpu\"),\n",
    "    \"device\" : \"GPU\" if tf.config.list_physical_devices('GPU') else \"CPU\",\n",
    "}\n",
    "\n",
    "print(f\"Using device: {CONFIG['device']}\")"
   ],
   "id": "dc4e686084c7dce0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6bdd5fd56cd32b5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sgkf = StratifiedGroupKFold(n_splits=CONFIG['n_fold'])\n",
    "\n",
    "for fold, ( _, val_) in enumerate(sgkf.split(df, df.target,df.patient_id)):\n",
    "      df.loc[val_ , \"kfold\"] = int(fold)"
   ],
   "id": "94ffde481aa18f52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "130379fe7f968017",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_transforms = {\n",
    "    \"train\": A.Compose([\n",
    "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.Flip(p=0.5),\n",
    "        A.Downscale(p=0.25),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, \n",
    "                           scale_limit=0.15, \n",
    "                           rotate_limit=60, \n",
    "                           p=0.5),\n",
    "        A.HueSaturationValue(\n",
    "                hue_shift_limit=0.2, \n",
    "                sat_shift_limit=0.2, \n",
    "                val_shift_limit=0.2, \n",
    "                p=0.5\n",
    "            ),\n",
    "        A.RandomBrightnessContrast(\n",
    "                brightness_limit=(-0.1,0.1), \n",
    "                contrast_limit=(-0.1, 0.1), \n",
    "                p=0.5\n",
    "            ),\n",
    "        A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "        # ToTensorV2()\n",
    "    ], p=1.),\n",
    "    \n",
    "    \"valid\": A.Compose([\n",
    "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "        A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "        # ToTensorV2()\n",
    "    ], p=1.)\n",
    "}\n"
   ],
   "id": "8e3891b8a888b9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def aug_fn(image, img_size, train):\n",
    "    data = {\"image\":image}\n",
    "    aug_data = data_transforms(**data[\"train\" if train else \"valid\"])\n",
    "    aug_img = aug_data[\"image\"]\n",
    "    aug_img = tf.cast(aug_img/255.0, tf.float32)\n",
    "    return tf.image.resize(aug_img, size=[img_size, img_size])"
   ],
   "id": "11d67e408bea3fb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def process_data(image, img_size):\n",
    "    aug_img = tf.numpy_function(func=aug_fn, inp=[image, img_size], Tout=tf.float32)\n",
    "    return aug_img"
   ],
   "id": "933c0d89859578ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e0b7d313b0149442",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "activation_func = 'gelu'\n",
    "# activation_func = 'relu'\n",
    "# activation_func = 'mish'\n",
    "\n",
    "num_epochs = 950\n",
    "learning_rate = 3.5e-4\n",
    "criterion = tf.keras.losses.MeanSquaredError()\n",
    "# criterion = tf.keras.losses.MeanAbsoluteError()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-5)"
   ],
   "id": "a560f9b8fec8ba7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import h5py\n",
    "\n",
    "# Loading images\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "with h5py.File('./data/train-image.hdf5', 'r') as f:\n",
    "       keys = list(f.keys())\n",
    "       for key in keys:\n",
    "           data = f[key]\n",
    "           if data.shape == () and data.dtype.kind == 'S':\n",
    "            try:\n",
    "                # Try decoding with latin-1\n",
    "                x_train.append(data[()].decode('latin-1'))\n",
    "            except UnicodeDecodeError:\n",
    "                print(f\"Failed to decode {key}, appending raw data\")\n",
    "                x_train.append(data[()]) \n",
    "               \n",
    "           \n",
    "           # x_train.append(f[key][:]) \n",
    "           y_train.append(key)\n",
    "              \n",
    "print(x_train.shape, y_train.shape)"
   ],
   "id": "fd5a77be29d925ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2ab45b1cd8b7d36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import h5py\n",
    "\n",
    "training_validation_hdf5 = h5py.File(f\"{ROOT_DIR}/train-image.hdf5\", 'r')\n",
    "testing_hdf5 = h5py.File(f\"{ROOT_DIR}/test-image.hdf5\", 'r')"
   ],
   "id": "d1609973c79f29c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "isic_id = df.isic_id.iloc[0]\n",
    "\n",
    "byte_string = training_validation_hdf5[isic_id][()]\n",
    "print(f\"Byte String: {byte_string[:20]}....\")\n",
    "\n",
    "nparr = np.frombuffer(byte_string, np.uint8)\n",
    "\n",
    "image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)[...,::-1] # reverse last axis for bgr -> rgb\n",
    "plt.imshow(image);"
   ],
   "id": "98588b5f4a13f7b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_ids = df.isic_id.values\n",
    "\n",
    "images = [None]*len(data_ids)\n",
    "for i, isic_id in enumerate(data_ids):\n",
    "    images[i] = training_validation_hdf5[isic_id][()]\n",
    "\n",
    "print(f\"Loaded {len(images)} images\")\n",
    "print(f\"First image shape: {cv2.imdecode(np.frombuffer(images[0], np.uint8), cv2.IMREAD_COLOR).shape}\")"
   ],
   "id": "ee95d87dcf594d05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4ef05ab2db516421",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# https://www.kaggle.com/code/awsaf49/isic2024-kerascv-starter\n",
    "\n",
    "def decoder(with_labels=True, target_size=(256, 256)):\n",
    "    \n",
    "    \n",
    "    def decode_image(inp):\n",
    "        \n",
    "        file_bytes = inp[\"images\"]\n",
    "        image = tf.io.decode_jpeg(file_bytes)\n",
    "        \n",
    "        image = tf.image.resize(image, size=target_size, method=\"area\")\n",
    "        \n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image /= 255.0\n",
    "  \n",
    "        image = tf.reshape(image, [*target_size, 3])\n",
    "        \n",
    "        inp[\"images\"] = image\n",
    "        return inp\n",
    "    \n",
    "    \n",
    "    def decode_label(label, num_classes):\n",
    "        label = tf.cast(label, tf.float32)\n",
    "        label = tf.reshape(label, [num_classes])\n",
    "        return label\n",
    "    \n",
    "  \n",
    "    def decode_with_labels(inp, label=None):\n",
    "        inp = decode_image(inp)\n",
    "        label = decode_label(label, 1)\n",
    "        return (inp, label)\n",
    "\n",
    "    return decode_with_labels if with_labels else decode_image\n",
    "\n",
    "decoder = decoder(with_labels=True, target_size=(CONFIG[\"img_size\"], CONFIG[\"img_size\"]))"
   ],
   "id": "3c586dcb09715b40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Too slow\n",
    "# decoded_images = [cv2.imdecode(np.frombuffer(img, np.uint8), cv2.IMREAD_COLOR)[...,::-1] for img in images]\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "inp = {\n",
    "    \"images\": images, \n",
    "    # \"features\": features\n",
    "       }\n",
    "\n",
    "slices = (inp, df.target.values)\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices(slices)\n",
    "ds = ds.cache()\n",
    "ds = ds.map(decoder, num_parallel_calls=AUTO)\n",
    "\n",
    "# ds = ds.shuffle(1024, seed=seed)\n",
    "# opt = tf.data.Options()\n",
    "# opt.deterministic = False\n",
    "# ds = ds.with_options(opt)\n",
    "\n",
    "ds = ds.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "# ds = ds.map(augment_fn, num_parallel_calls=AUTO)\n",
    "ds = ds.prefetch(AUTO)"
   ],
   "id": "e267213acbd77be3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ds.cardinality()",
   "id": "c9a6a1dd5c09741",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ds.shuffle(1024, seed=42)\n",
    "ds_size = ds.cardinality().numpy()\n",
    "\n",
    "train_size = int(0.8 * ds_size)\n",
    "\n",
    "train_ds = ds.take(train_size)\n",
    "valid_ds = ds.skip(train_size)"
   ],
   "id": "ac2858ec7adae86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "batch = next(iter(train_ds))\n",
    "\n",
    "print(\"Images:\",batch[0][\"images\"].shape)\n",
    "# print(\"Features:\", batch[0][\"features\"].shape)\n",
    "print(\"Targets:\", batch[1].shape)"
   ],
   "id": "77b23795a15fe845",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# train_loader = list(train_ds.as_numpy_iterator())",
   "id": "ba0a95b99805e7c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# list(train_ds.as_numpy_iterator())",
   "id": "d32c24d24666c571",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Too slow\n",
    "x_train = [cv2.imread(img) for img in train_ds['file_path'].values]\n",
    "x_train = [cv2.cvtColor(img, cv2.COLOR_BGR2RGB) for img in x_train]\n",
    "x_train = [img.map(partial(process_data), num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE) for img in x_train]\n",
    "\n",
    "y_train = train_ds['target'].values\n",
    "x_valid = [cv2.imread(img) for img in valid_ds['file_path'].values]\n",
    "y_valid = valid_ds['target'].values\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "x_train[0].shape"
   ],
   "id": "5e48fb9c3c100575",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(train_ds, dtype=tf.float32),\n",
    "                                                    tf.convert_to_tensor(y_train, dtype=tf.float32)))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(x_valid, dtype=tf.float32),\n",
    "                                                  tf.convert_to_tensor(y_valid, dtype=tf.float32)))\n",
    "\n",
    "train_loader = train_dataset.shuffle(buffer_size=len(x_train)).batch(batch_size, drop_remainder=True)\n",
    "val_loader = val_dataset.shuffle(buffer_size=len(val_dataset)).batch(batch_size, drop_remainder=True)"
   ],
   "id": "a0a5fb2a97ee4237",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Net(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.input_layer = keras.Input(shape=(384, 384, 3), name=\"images\")\n",
    "\n",
    "        # self.input_layer = tf.keras.layers.Dense(shape=(, 384, 384, 3), activation=activation_func)\n",
    "\n",
    "        # self.feature_extractor = []\n",
    "        # for i in range(5):\n",
    "        #     self.hidden_layers.append(tf.keras.layers.Dense(2048, activation=activation_func))\n",
    "        #     self.hidden_layers.append(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "        self.hidden_layers = []\n",
    "        for i in range(17):\n",
    "            self.hidden_layers.append(tf.keras.layers.Dense(1024, activation=activation_func))\n",
    "            self.hidden_layers.append(tf.keras.layers.Dropout(0.2))\n",
    "            self.hidden_layers.append(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "        self.additional_layers = []\n",
    "        for i in range(2):\n",
    "            self.additional_layers.append(tf.keras.layers.Dense(512, activation=activation_func))\n",
    "            self.additional_layers.append(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "        self.output_layer = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.input_layer(x[0][\"images\"])\n",
    "        # for layer in self.feature_extractor:\n",
    "        #     x = layer(x)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        for layer in self.additional_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return self.output_layer(x)\n",
    "\n",
    "model = Net()"
   ],
   "id": "66f66a3312c72691",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_loader = train_ds\n",
    "val_loader = valid_ds\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "    train_loss = 0\n",
    "    for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = model(batch_x, training=True)\n",
    "            loss = criterion(batch_y, tf.squeeze(outputs))\n",
    "\n",
    "        grads = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        train_loss += loss.numpy()\n",
    "\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "    # Validation loop\n",
    "    val_loss = 0\n",
    "    for batch_x, batch_y in val_loader:\n",
    "        outputs = model(batch_x, training=False)\n",
    "        loss = criterion(batch_y, tf.squeeze(outputs))\n",
    "        val_loss += loss.numpy()\n",
    "\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}/{num_epochs}, \"\n",
    "        f\"Train Loss: {train_loss / len(train_loader):.4f}, \"\n",
    "        f\"Validation Loss: {val_loss / len(val_loader):.4f}\"\n",
    "    )"
   ],
   "id": "9cc53dd86cba149e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "train_losses = np.array(train_losses)\n",
    "val_losses = np.array(val_losses)"
   ],
   "id": "feca4cc3f5ea2bb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Set model to inference mode (not strictly necessary in TensorFlow as it handles this automatically)\n",
    "# Making predictions on training and testing data\n",
    "x_train_tensor = tf.convert_to_tensor(x_train, dtype=tf.float32)\n",
    "x_test_tensor = tf.convert_to_tensor(x_test, dtype=tf.float32)\n",
    "\n",
    "y_train_pred = model(x_train_tensor, training=False).numpy()\n",
    "y_test_pred = model(x_test_tensor, training=False).numpy()"
   ],
   "id": "c0a2d496d458f0f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(f'Train R-squared: {train_r2 * 100:.2f}%')\n",
    "print(f'Test R-squared: {test_r2 * 100:.2f}%')\n",
    "print(f'Test Mean Squared Error (MSE): {test_mse:.2f}')\n",
    "print(f'Test Root Mean Squared Error (RMSE): {test_rmse:.2f}')\n",
    "print(f'Test Mean Absolute Error (MAE): {test_mae:.2f}')\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(y_test, label='Actual', marker='o', linestyle='None')\n",
    "plt.plot(y_test_pred, label='Predicted', marker='x', linestyle='None')\n",
    "plt.legend()\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "print(model.summary())\n",
    "print(model.get_config())\n",
    "print(optimizer.get_config())\n",
    "print(model.loss)"
   ],
   "id": "97484a6d21da814a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3e1d78cbea36b968",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Transfer Learning [freeze all layers of feature extractor]: Functional API\n",
    "\n",
    "base_model = keras.applications.ResNet50(include_top=False, input_shape=(CONFIG[\"img_size\"], CONFIG[\"img_size\"], 3), weights=\"imagenet\")\n",
    "base_model.trainable = False\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "    def __init__(self, base_model):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.base = base_model\n",
    "        self.layer_1 = keras.layers.Flatten()\n",
    "        self.layer_2 = keras.layers.Dense(64, activation='relu')\n",
    "        self.layer_3 = keras.layers.Dense(1, activation='softmax')\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, xb):\n",
    "        x = self.base(xb)\n",
    "        x = self.layer_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        return self.layer_3(x)\n",
    "\n",
    "\n",
    "model = MyModel(base_model=base_model)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "model.fit(train_data, epochs=2)"
   ],
   "id": "18ee31852327fef4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
