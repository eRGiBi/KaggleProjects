{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b260f5b3bb829a73",
   "metadata": {},
   "source": [
    "\n",
    "# ISIC 2024 - Skin Cancer Detection with 3D-TBP\n",
    "\n",
    "Nicholas Kurtansky, Veronica Rotemberg, Maura Gillis, Kivanc Kose, Walter Reade, Ashley Chow. (2024). ISIC 2024 - Skin Cancer Detection with 3D-TBP. Kaggle. \n",
    "\n",
    "https://kaggle.com/competitions/isic-2024-challenge\n",
    "\n",
    "Currently heavily in development."
   ]
  },
  {
   "cell_type": "code",
   "id": "2c1f0d5502d23b8d",
   "metadata": {},
   "source": [
    "import os\n",
    "import os.path as path\n",
    "import gc\n",
    "# import cv2\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "import h5py\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# from torch.optim import lr_scheduler\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torch.cuda import amp\n",
    "# import torchvision\n",
    "# from torcheval.metrics.functional import binary_auroc\n",
    " \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold \n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# import timm\n",
    "\n",
    "import albumentations as A\n",
    "# from albumentations.pytorch import ToTensorV2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "af1f8aa9ef07d246",
   "metadata": {},
   "source": [
    "# Variables\n",
    "\n",
    "seed = 476\n",
    "TIME = time.strftime(\"%m-%d-%H-%M-%S\")\n",
    "\n",
    "env_cfg = {\n",
    "    \"seed\": seed,\n",
    "    # \"device\": nn.device(\"cuda:0\" if nn.cuda. else \"cpu\"),\n",
    "    \"device\" : \"GPU\" if tf.config.list_physical_devices('GPU') else \"CPU\",\n",
    "    \"verbosity\": '3',\n",
    "}\n",
    "device = \"GPU\" if tf.config.list_physical_devices('GPU') else \"CPU\"\n",
    "verbosity = '3'\n",
    "\n",
    "CONFIG = {\n",
    "    \"seed\": seed, \n",
    "    \"img_size\": 384,\n",
    "    \"model_name\": \"\",\n",
    "    \"checkpoint_path\" : \"/ISIC2024_SkinCancerDetection/saved_models\",\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img_size = 384\n",
    "chekpoint_path = \"/ISIC2024_SkinCancerDetection/saved_models\""
   ],
   "id": "57995d21c3a06c8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"At: {TIME}\")"
   ],
   "id": "e2a6a118b6308d31",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cbbfd15a",
   "metadata": {},
   "source": [
    "# Neural net hyperparameters \n",
    "\n",
    "# activation_func = 'gelu'\n",
    "activation_func = 'relu'\n",
    "# activation_func = 'mish'\n",
    "batch_size = 16\n",
    "num_epochs = 40\n",
    "learning_rate = 1e-5\n",
    "criterion = tf.keras.losses.BinaryCrossentropy()\n",
    "# criterion = tf.keras.losses.MeanAbsoluteError()\n",
    "# criterion = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\n",
    "\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=CONFIG[\"seed\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3818397e011fe631",
   "metadata": {},
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = env_cfg[\"verbosity\"]\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = env_cfg[\"verbosity\"]\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fa199a14",
   "metadata": {},
   "source": [
    "# os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"false\"\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\".XX\"\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\"\n",
    "\n",
    "tf.debugging.set_log_device_placement(False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fcc4d3503a76c82b",
   "metadata": {},
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e9800f6d5fd076a6",
   "metadata": {},
   "source": [
    "def set_seed(seed=42):\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    \n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "    \n",
    "    # torch.manual_seed(seed)\n",
    "    # torch.cuda.manual_seed(seed)\n",
    "  \n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "    # torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "set_seed(seed)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cbc6df94436a8e14",
   "metadata": {},
   "source": [
    "# https://www.kaggle.com/code/motono0223/isic-pytorch-training-baseline-image-only#Training-Function\n",
    "\n",
    "ROOT_DIR = path.normpath(\"./data/\")\n",
    "TRAIN_DIR = f'{ROOT_DIR}/train-image/image/'\n",
    "\n",
    "train_images = sorted(glob.glob(f\"{TRAIN_DIR}/*.jpg\"))\n",
    "print(TRAIN_DIR)\n",
    "print(\"Number of train_images:\", len(train_images))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "34a0135258a81a2a",
   "metadata": {},
   "source": [
    "train_images[:5]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "702e6a1c7ceec21d",
   "metadata": {},
   "source": [
    "def get_train_file_path(image_id):\n",
    "    return f\"{TRAIN_DIR}/{image_id}.jpg\"\n",
    "\n",
    "print(get_train_file_path(\"ISIC_0015864\"))\n",
    "# img = cv2.imread(get_train_file_path(\"ISIC_0015864\"))\n",
    "\n",
    "# plt.imshow(img)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8f29376d58197683",
   "metadata": {},
   "source": [
    "df = pd.read_csv(f\"{ROOT_DIR}/train-metadata.csv\")\n",
    "\n",
    "df.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1435e240",
   "metadata": {},
   "source": [
    "df.describe(include=\"all\").T"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eb0965b2",
   "metadata": {},
   "source": [
    "id_values = df[\"patient_id\"].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(id_values, bins=50, kde=False)\n",
    "plt.yscale('log')\n",
    "plt.title('Distribution of Number of Images per Patient')\n",
    "plt.xlabel('Number of Images')\n",
    "plt.ylabel('Frequency (log scale)')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f9b43db1",
   "metadata": {},
   "source": [
    "patient_with_most_images = id_values.idxmax()\n",
    "most_images_count = id_values.max()\n",
    "\n",
    "print(f\"Patient ID with the most images: {patient_with_most_images}\")\n",
    "print(f\"Number of images: {most_images_count}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "09fdaaa0",
   "metadata": {},
   "source": [
    "patient_with_most_images_entries = df[df.patient_id  == patient_with_most_images]\n",
    "print(patient_with_most_images_entries)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cbd67d11fb95b117",
   "metadata": {},
   "source": [
    "df_positive = df[df[\"target\"] == 1].reset_index(drop=True)\n",
    "df_negative = df[df[\"target\"] == 0].reset_index(drop=True)\n",
    "\n",
    "print(\"Unique patients:\",  df[\"patient_id\"].unique().shape[0])\n",
    "print()\n",
    "\n",
    "print(\"Positive patient images:\", df_positive.shape[0])\n",
    "print(\"Unique patients with positive images:\",  df_positive[\"patient_id\"].unique().shape[0])\n",
    "print()\n",
    "\n",
    "print(\"Negative patient images:\", df_negative.shape[0])\n",
    "print(\"Unique patients with negative images:\",  df_negative[\"patient_id\"].unique().shape[0])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "df418174",
   "metadata": {},
   "source": [
    "neg, pos = df[\"target\"].value_counts()\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "890bcc0e",
   "metadata": {},
   "source": [
    "# Imbalanced dataset fix\n",
    "\n",
    "df = pd.concat([df_positive, df_negative.iloc[:df_positive.shape[0]*7, :]])  \n",
    "print(\"Reduced dataset shape:\", df.shape, df.target.sum(), df[\"patient_id\"].unique().shape)\n",
    "\n",
    "df['file_path'] = df['isic_id'].apply(get_train_file_path)\n",
    "\n",
    "# df = df[ df[\"file_path\"].isin(train_images) ].reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d6080202dd229c21",
   "metadata": {},
   "source": [
    "print(\"Number of unique patients after balancing: \", df[\"patient_id\"].nunique())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3b78a46923850c84",
   "metadata": {},
   "source": [
    "name = ['Benign', 'Malignant']\n",
    "\n",
    "plt.figure(figsize = (5, 5))\n",
    "plt.pie(df.target.value_counts(normalize = True), autopct = '%1.1f%%', startangle = 90, wedgeprops = dict(width = 0.3), \n",
    "        labeldistance = 1.2, radius = 1)\n",
    "plt.title(f'Total Target Distribution', color = 'black', fontsize = 15)\n",
    "plt.legend(name,)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a21d8c1738cc0ed5",
   "metadata": {},
   "source": [
    "missing_values_count = df.isnull().sum()\n",
    "print(sorted(missing_values_count, reverse=True))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8e3891b8a888b9d",
   "metadata": {},
   "source": [
    "multi_data_transforms = {\n",
    "    \"train\": A.Compose([\n",
    "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Flip(p=0.5),\n",
    "        A.Downscale(p=0.25),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, \n",
    "                           scale_limit=0.15, \n",
    "                           rotate_limit=60, \n",
    "                           p=0.5),\n",
    "        A.HueSaturationValue(\n",
    "                hue_shift_limit=0.2, \n",
    "                sat_shift_limit=0.2, \n",
    "                val_shift_limit=0.2, \n",
    "                p=0.5\n",
    "            ),\n",
    "        A.RandomBrightnessContrast(\n",
    "                brightness_limit=(-0.1,0.1), \n",
    "                contrast_limit=(-0.1, 0.1), \n",
    "                p=0.5\n",
    "            ),\n",
    "        A.Normalize(\n",
    "                # mean=[0.485, 0.456, 0.406], \n",
    "                # std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "        # ToTensorV2()\n",
    "    ], p=1.\n",
    "                       ),\n",
    "    \n",
    "    \"valid\": A.Compose([\n",
    "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "        A.Normalize(\n",
    "                # mean=[0.485, 0.456, 0.406], \n",
    "                # std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "        # ToTensorV2()\n",
    "        ], p=1.\n",
    "                       )\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8a2b9a67",
   "metadata": {},
   "source": [
    "single_transforms = A.Compose([\n",
    "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Flip(p=0.5),\n",
    "        A.Downscale(p=0.25),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, \n",
    "                           scale_limit=0.15, \n",
    "                           rotate_limit=60, \n",
    "                           p=0.5),\n",
    "        A.HueSaturationValue(\n",
    "                hue_shift_limit=0.2, \n",
    "                sat_shift_limit=0.2, \n",
    "                val_shift_limit=0.2, \n",
    "                p=0.5\n",
    "            ),\n",
    "        A.RandomBrightnessContrast(\n",
    "                brightness_limit=(-0.1,0.1), \n",
    "                contrast_limit=(-0.1, 0.1), \n",
    "                p=0.5\n",
    "            ),\n",
    "        A.Normalize(\n",
    "                # mean=[0.485, 0.456, 0.406], \n",
    "                # std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "        # ToTensorV2()\n",
    "    ], p=1.\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "11d67e408bea3fb7",
   "metadata": {},
   "source": [
    "def mult_aug_fn(image, img_size, train):\n",
    "    data = {\"image\":image}\n",
    "    aug_data = multi_data_transforms(**data[\"train\" if train else \"valid\"])\n",
    "    aug_img = aug_data[\"image\"]\n",
    "    aug_img = tf.cast(aug_img/255.0, tf.float32)\n",
    "    return tf.image.resize(aug_img, size=[img_size, img_size])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0458d4a2",
   "metadata": {},
   "source": [
    "def apply_single_img_augmentation(image, img_size=CONFIG['img_size']):\n",
    "    image = np.array(image)\n",
    "    \n",
    "    if image.shape[0] <= 0 or image.shape[1] <= 0:\n",
    "        raise ValueError(\"Image has non-positive dimensions\")\n",
    "    \n",
    "    aug_data = single_transforms(image=image)\n",
    "    aug_img = aug_data[\"image\"]\n",
    "    \n",
    "    # image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "    \n",
    "    aug_img = tf.cast(aug_img/255.0, tf.float32)\n",
    "    resized = tf.image.resize(aug_img, size=[img_size, img_size])\n",
    "\n",
    "    return resized"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "933c0d89859578ad",
   "metadata": {},
   "source": [
    "def augment_multi_modal(image, img_size):\n",
    "    aug_img = tf.numpy_function(func=mult_aug_fn, inp=[image, img_size], Tout=tf.float32)\n",
    "    return aug_img"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "145f07d9",
   "metadata": {},
   "source": [
    "def augment_single_img(image, label, img_size=CONFIG['img_size']):\n",
    "    aug_img = tf.numpy_function(func=apply_single_img_augmentation, inp=[image, img_size], Tout=tf.float32)\n",
    "    aug_img.set_shape([img_size, img_size, 3])\n",
    "    # ensure_shape\n",
    "    \n",
    "    return aug_img, label"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fd5a77be29d925ac",
   "metadata": {},
   "source": [
    "# Manual loading, too slow\n",
    "# x_train = []\n",
    "# y_train = []\n",
    "# with h5py.File('ISIC2024_SkinCancerDetection/data/train-image.hdf5', 'r') as f:\n",
    "#        keys = list(f.keys())\n",
    "#        for key in keys:\n",
    "#            data = f[key]\n",
    "#            x_train.append(data[()].decode('latin-1'))\n",
    "#            \n",
    "#            # x_train.append(f[key][:]) \n",
    "#            y_train.append(key)\n",
    "#               \n",
    "# print(len(x_train), len(y_train))\n",
    "# print(x_train[:5], y_train[:5])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d1609973c79f29c",
   "metadata": {},
   "source": [
    "training_validation_hdf5 = h5py.File(f\"{ROOT_DIR}/train-image.hdf5\", 'r', libver='earliest')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "98588b5f4a13f7b2",
   "metadata": {},
   "source": [
    "# Example\n",
    "\n",
    "isic_id = df.isic_id.iloc[10]\n",
    "\n",
    "byte_string = training_validation_hdf5[isic_id][()]\n",
    "# print(f\"Byte String: {byte_string[:20]}....\")\n",
    "\n",
    "nparr = np.frombuffer(byte_string, np.uint8)\n",
    "\n",
    "# image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)[...,::-1] # reverse last axis for bgr -> rgb\n",
    "#print(f\"Image: {image}\")\n",
    "\n",
    "# plt.imshow(image);\n",
    "# print(f\"First image shape: {image.shape}.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ee95d87dcf594d05",
   "metadata": {},
   "source": [
    "# Load all images\n",
    "\n",
    "data_ids = df.isic_id.values\n",
    "\n",
    "images = [None]*len(data_ids)\n",
    "for i, isic_id in enumerate(data_ids):\n",
    "    images[i] = training_validation_hdf5[isic_id][()]\n",
    "\n",
    "print(f\"Loaded {len(images)} images.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2e658777",
   "metadata": {},
   "source": [
    "# import concurrent.futures\n",
    "# from PIL import Image\n",
    "\n",
    "# def load_and_convert_image(image_path):\n",
    "#     # img = cv2.imread(image_path)\n",
    "#     # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     # return img\n",
    "#     with Image.open(image_path) as img:\n",
    "#         img = img.convert('RGB')\n",
    "#         img = img.resize((CONFIG[\"img_size\"], CONFIG[\"img_size\"]))\n",
    "#         return np.array(img)\n",
    "\n",
    "# with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "#     mg = list(executor.map(load_and_convert_image, train_images))\n",
    "\n",
    "# print(f\"Loaded {len(mg)} images.\")\n",
    "# print(f\"First image shape: {mg[0].shape}.\")\n",
    "# print(f\"First image: {mg[0]}.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4ef05ab2db516421",
   "metadata": {},
   "source": [
    "# hist = [cv2.calcHist([cv2.imdecode(np.frombuffer(img, np.uint8), cv2.IMREAD_COLOR)], [0], None, [256], [0, 256]) for img in images]\n",
    "# hist = np.array(hist).squeeze()\n",
    "# plt.plot(hist[0], label=\"Blue\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3c586dcb09715b40",
   "metadata": {},
   "source": [
    "# Based on https://www.kaggle.com/code/awsaf49/isic2024-kerascv-starter\n",
    "\n",
    "def decoder(only_image=False, with_labels=True, target_size=(256, 256)):\n",
    "    \n",
    "    def decode_only_image(file_bytes, label):\n",
    "        \n",
    "        image = tf.io.decode_jpeg(file_bytes)\n",
    "        \n",
    "        image = tf.image.resize(image, size=target_size, method=\"area\")\n",
    "        \n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image /= 255.0\n",
    "  \n",
    "        image = tf.reshape(image, [*target_size, 3])\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def decode_image(inp):\n",
    "        \n",
    "        file_bytes = inp[\"images\"]\n",
    "        image = tf.io.decode_jpeg(file_bytes)\n",
    "        \n",
    "        image = tf.image.resize(image, size=target_size, method=\"area\")\n",
    "        \n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image /= 255.0\n",
    "  \n",
    "        image = tf.reshape(image, [*target_size, 3])\n",
    "        \n",
    "        inp[\"images\"] = image\n",
    "        return inp\n",
    "    \n",
    "    \n",
    "    def decode_label(label, num_classes):\n",
    "        label = tf.cast(label, tf.float32)\n",
    "        label = tf.reshape(label, [num_classes])\n",
    "        return label\n",
    "    \n",
    "  \n",
    "    def decode_with_labels(inp, label=None):\n",
    "        inp = decode_image(inp)\n",
    "        label = decode_label(label, 1)\n",
    "        return inp, label\n",
    "    \n",
    "    if only_image:\n",
    "        return decode_only_image\n",
    "    return decode_with_labels if with_labels else decode_image\n",
    "\n",
    "multi_decoder = decoder(with_labels=False, target_size=(CONFIG[\"img_size\"], CONFIG[\"img_size\"]))\n",
    "image_decoder = decoder(only_image=True, with_labels=False, target_size=(CONFIG[\"img_size\"], CONFIG[\"img_size\"]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "376689eb06cd0c2a",
   "metadata": {},
   "source": [
    "# Too slow\n",
    "# decoded_images = [cv2.imdecode(np.frombuffer(img, np.uint8), cv2.IMREAD_COLOR)[...,::-1] for img in images]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e267213acbd77be3",
   "metadata": {},
   "source": [
    "# Multimodal dataset\n",
    "\n",
    "# inp = {\n",
    "#     \"images\": images, \n",
    "#     \"features\": features\n",
    "#        }\n",
    "\n",
    "# slices = (inp, df.target.values)\n",
    "\n",
    "# ds = tf.data.Dataset.from_tensor_slices(slices)\n",
    " \n",
    "# ds = tf.data.Dataset.from_tensor_slices(images, df.target.values)\n",
    "# ds = ds.cache()\n",
    "# ds = ds.map(decoder, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# ds = ds.shuffle(1024, seed=seed)\n",
    "# opt = tf.data.Options()\n",
    "# opt.deterministic = False\n",
    "# ds = ds.with_options(opt)\n",
    "\n",
    "# ds = ds.batch(CONFIG['train_batch_size'], drop_remainder=True)\n",
    "\n",
    "# ds = ds.map(augment_fn, num_parallel_calls=AUTOTUNE)\n",
    "# ds = ds.prefetch(AUTOTUNE)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "df9cceac943f4b1e",
   "metadata": {},
   "source": [
    "# Manual decoding, too slow\n",
    "\n",
    "# decoded_images = []\n",
    "# target_size=(CONFIG[\"img_size\"], CONFIG[\"img_size\"])\n",
    "# \n",
    "# for file_bytes in images:\n",
    "#     with tf.device(\"/CPU:0\"):\n",
    "#         image = tf.io.decode_jpeg(file_bytes)\n",
    "# \n",
    "#         image = tf.image.resize(image, size=target_size, method=\"area\")\n",
    "# \n",
    "#         image = tf.cast(image, tf.float32)\n",
    "#         image /= 255.0\n",
    "# \n",
    "#         image = tf.reshape(image, [*target_size, 3])\n",
    "# \n",
    "#         decoded_images.append(image)\n",
    "# \n",
    "# decoded_images = tf.stack(decoded_images)\n",
    "# \n",
    "# decoded_images_np = decoded_images.numpy()\n",
    "# \n",
    "# \n",
    "# print(decoded_images_np.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "90e4705a",
   "metadata": {},
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print(\"Memory growth not supported.\")\n",
    "    pass\n",
    "    # Invalid device or cannot modify virtual devices once initialized."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b5080dc6",
   "metadata": {},
   "source": [
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth=True\n",
    "# sess = tf.Session(config=config)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5acbf3ea",
   "metadata": {},
   "source": [
    "tf.config.experimental.get_memory_info('GPU:0')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f3287838",
   "metadata": {},
   "source": [
    "image = images[23]\n",
    "decoded_image = image_decoder(image, df.target.values[0])\n",
    "# print(decoded_image)\n",
    "augmented_image = single_transforms(image=np.array(decoded_image[0]))\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "arr = (np.asarray(decoded_image[0].numpy()) * 255).astype(np.uint8)\n",
    "\n",
    "print(arr.shape)\n",
    "\n",
    "# Image.fromarray((decoded_image[0].numpy() * 255).astype(np.uint8) ).show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5f437b68",
   "metadata": {},
   "source": "# Image.fromarray(arr).show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7fde1b9430f06e59",
   "metadata": {},
   "source": [
    "# Single image dataset\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images, df.target.values))\n",
    "\n",
    "print(f\"Dataset size: {dataset.cardinality().numpy()}\")\n",
    "\n",
    "dataset = dataset.map(image_decoder, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "augmented_dataset = dataset.map(augment_single_img, num_parallel_calls=AUTOTUNE)\n",
    "dataset = dataset.concatenate(augmented_dataset)\n",
    "\n",
    "print(f\"Dataset size: {dataset.cardinality().numpy()}\")\n",
    "\n",
    "dataset = dataset.cache()\n",
    "\n",
    "# dataset = dataset.shuffle(buffer_size=ds_size)\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    train_ds, valid_ds = tf.keras.utils.split_dataset(dataset, left_size=0.8, shuffle=True, seed=seed)\n",
    "\n",
    "train_ds = train_ds.cache()\n",
    "valid_ds = valid_ds.cache()\n",
    "\n",
    "print(f\"Training dataset size: {train_ds.cardinality().numpy()}\")\n",
    "print(f\"Validation dataset size: {valid_ds.cardinality().numpy()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "del dataset",
   "id": "b84767ee717146f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# train_size = int(0.8 * ds_size)\n",
    "# train_ds = dataset.take(train_size)\n",
    "# valid_ds = dataset.skip(train_size)\n",
    "\n",
    "# train_labels = [sample[1] for sample in train_ds.as_numpy_iterator()]\n",
    "# valid_labels = [sample[1] for sample in valid_ds.as_numpy_iterator()]\n",
    "train_labels = [labels.numpy() for _, labels in train_ds]\n",
    "valid_labels = [labels.numpy() for _, labels in valid_ds]\n",
    "\n",
    "# Apply batching\n",
    "train_ds = train_ds.batch(batch_size=batch_size, drop_remainder=True)\n",
    "valid_ds = valid_ds.batch(batch_size=batch_size, drop_remainder=True)\n",
    "\n",
    "# Prefetch for performance\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "valid_ds = valid_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(f\"Training dataset size: {train_ds.cardinality().numpy()}\")\n",
    "print(f\"Validation dataset size: {valid_ds.cardinality().numpy()}\")"
   ],
   "id": "1052ea6f99df5034",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Sanity check\n",
    "\n",
    "# train_labels, valid_labels = [], []\n",
    "# \n",
    "# train_hashes = set()\n",
    "# valid_hashes = set()\n",
    "# \n",
    "# optional_computing = False\n",
    "# \n",
    "# # Convert images to hashes for faster comparison\n",
    "# for img, label in train_ds.unbatch().as_numpy_iterator():\n",
    "#     if optional_computing:\n",
    "#         train_hashes.add(hash(img.tobytes()))\n",
    "#     train_labels.append(label)\n",
    "# \n",
    "# for img, label in valid_ds.unbatch().as_numpy_iterator():\n",
    "#     if optional_computing:\n",
    "#         valid_hashes.add(hash(img.tobytes()))\n",
    "#     valid_labels.append(label)\n",
    "# \n",
    "# if optional_computing:\n",
    "#     duplicates = []\n",
    "#     for img_hash in train_hashes.keys():\n",
    "#         if img_hash in valid_hashes:\n",
    "#             duplicates.append((train_hashes[img_hash], valid_hashes[img_hash]))\n",
    "#             \n",
    "#     print(f\"Number of duplicates: {len(duplicates)}\")\n",
    "#     print(duplicates)\n",
    "# \n",
    "# del train_hashes, valid_hashes"
   ],
   "id": "8b71e61a42a97936",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f0a3ee31",
   "metadata": {},
   "source": [
    "train_labels = np.array(train_labels)\n",
    "valid_labels = np.array(valid_labels)\n",
    "\n",
    "print(f'Average class probability in training set:   {train_labels.mean():.4f}')\n",
    "print(f'Average class probability in validation set: {valid_labels.mean():.4f}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e9c740a3",
   "metadata": {},
   "source": [
    "# train_c = 0\n",
    "# val_c = 0\n",
    "# \n",
    "# for batch in train_ds:\n",
    "#     train_c += sum(batch[1])\n",
    "# \n",
    "# for batch in valid_ds:\n",
    "#     val_c += sum(batch[1])\n",
    "# \n",
    "# print(train_c, val_c)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d6daf5ed",
   "metadata": {},
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryCrossentropy(name='cross entropy'),\n",
    "      tf.keras.metrics.MeanSquaredError(name='Brier score'),\n",
    "      tf.keras.metrics.TruePositives(name='tp'),\n",
    "      tf.keras.metrics.FalsePositives(name='fp'),\n",
    "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "      tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "      tf.keras.metrics.AUC(name='prc', curve='PR'),\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b11821a2",
   "metadata": {},
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)    \n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "66f66a3312c72691",
   "metadata": {},
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-5)\n",
    "\n",
    "class Net(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        #self.flatten_layer = keras.layers.Flatten(name=\"flatten\")\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), \n",
    "                                            input_shape=(batch_size, 384, 384, 3),\n",
    "                                            activation=activation_func\n",
    "                                            )\n",
    "        # self.pool1 = (tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), \n",
    "                                            activation=activation_func, \n",
    "                                            # strides=(2, 2)\n",
    "                                            )\n",
    "        self.pool2 = (tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "        self.conv3 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                                            activation=activation_func,\n",
    "                                            # strides=(2, 2)\n",
    "                                            )\n",
    "        # self.pool3 = (tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "        self.conv4 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                                            activation=activation_func\n",
    "                                            )\n",
    "        self.pool4 = (tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "        self.conv5 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                                            activation=activation_func\n",
    "                                            )\n",
    "        \n",
    "        self.conv55 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                                            activation=activation_func\n",
    "                                            )\n",
    "        self.pool5 = (tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "        self.conv6 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3),\n",
    "                                            activation=activation_func\n",
    "                                            )\n",
    "        self.pool6 = (tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "        self.conv7 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3),\n",
    "                                            activation=activation_func\n",
    "                                            )\n",
    "        self.conv8 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3),\n",
    "                                            activation=activation_func\n",
    "                                            )\n",
    "        self.pool7 = (tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "        # self.conv8 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3),\n",
    "        #                                     activation=activation_func\n",
    "        #                                     )\n",
    "        \n",
    "        # self.conv9 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3),\n",
    "        #                                     activation=activation_func\n",
    "        #                                     )\n",
    "        # self.pool8 = (tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "        \n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "    \n",
    "\n",
    "        # self.feature_extractor = []\n",
    "        # for i in range(5):\n",
    "        #     self.hidden_layers.append(tf.keras.layers.Dense(2048, activation=activation_func))\n",
    "        #     self.hidden_layers.append(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "        self.hidden_layers = []\n",
    "        for i in range(1):\n",
    "            self.hidden_layers.append(tf.keras.layers.Dense(512, activation=activation_func, \n",
    "                                                            kernel_initializer=\"he_normal\",\n",
    "                                                            kernel_regularizer=tf.keras.regularizers.L1(0.01))\n",
    "                                      )\n",
    "            self.hidden_layers.append(tf.keras.layers.Dropout(0.3))\n",
    "            self.hidden_layers.append(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "        self.additional_layers = []\n",
    "        for i in range(1):\n",
    "            self.additional_layers.append(tf.keras.layers.Dense(256, activation=activation_func,\n",
    "                                                                kernel_initializer=\"he_normal\",\n",
    "                                                                kernel_regularizer=tf.keras.regularizers.L1(0.01))\n",
    "                                          )\n",
    "            self.hidden_layers.append(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "        self.output_layer = tf.keras.layers.Dense(1, \n",
    "                                                  activation='sigmoid',\n",
    "                                                #   bias_initializer=tf.keras.initializers.Constant(np.log([pos/neg]))\n",
    "                                                  )\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        # x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        # x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv55(x)\n",
    "        x = self.pool5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.pool6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.pool7(x)\n",
    "        # x = self.conv8(x)\n",
    "        # x = self.conv9(x)\n",
    "        # x = self.pool8(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        # for layer in self.feature_extractor:\n",
    "        #     x = layer(x)\n",
    "\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        for layer in self.additional_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return self.output_layer(x)\n",
    "\n",
    "model = Net()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6a06b9f8",
   "metadata": {},
   "source": [
    "# Callbacks\n",
    "\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(\n",
    "    f\"{ROOT_DIR}/chkpts/checkpoint.keras.model{TIME}\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode=\"max\",\n",
    "    save_freq=\"epoch\",\n",
    "    initial_value_threshold=0.85,\n",
    "), tf.keras.callbacks.TensorBoard(log_dir=f\"{ROOT_DIR}/logs\",\n",
    "                                  histogram_freq=0,\n",
    "                                  write_steps_per_second=True,\n",
    "                                  write_images=False,\n",
    "                                  ), tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10,\n",
    "                                                                      restore_best_weights=True,\n",
    "                                                                      verbose=1\n",
    "                                                                      ), tf.keras.callbacks.ProgbarLogger()]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "99dc4214",
   "metadata": {},
   "source": [
    "# Class weights\n",
    "\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0) # * (1/8)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2d0c2f6b",
   "metadata": {},
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "sk_class_weights = dict(enumerate(\n",
    "    class_weight.compute_class_weight('balanced', \n",
    "                                      classes=[0, 1], \n",
    "                                      y=np.concatenate([train_labels, valid_labels])\n",
    "                                      )\n",
    "                                  )\n",
    "                        )\n",
    "\n",
    "print(\"SK Weights:\", sk_class_weights)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5cfc0b73745ec707",
   "metadata": {},
   "source": "model.compile(optimizer=optimizer, loss=criterion, metrics=['accuracy', f1_m, precision_m, recall_m])",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ec21a0858b9e1f64",
   "metadata": {},
   "source": [
    "history = model.fit(train_ds, epochs=num_epochs, validation_data=valid_ds, callbacks=callbacks, \n",
    "                    # class_weight=sk_class_weights,\n",
    "                    use_multiprocessing=True,\n",
    "                    verbose=2\n",
    "                    )   "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aefbac7c",
   "metadata": {},
   "source": [
    "model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "10ea6d28",
   "metadata": {},
   "source": [
    "results = model.evaluate(valid_ds)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "11eff8fe",
   "metadata": {},
   "source": [
    "initial_bias = np.log([pos/neg])\n",
    "initial_bias"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a67d6dae",
   "metadata": {},
   "source": [
    "def plot_loss(history, label, n):\n",
    "  \n",
    "  plt.semilogy(history.epoch, history.history['loss'],\n",
    "               color=colors[n], label='Train ' + label)\n",
    "  \n",
    "  plt.semilogy(history.epoch, history.history['val_loss'],\n",
    "               color=colors[n], label='Val ' + label,\n",
    "               linestyle=\"--\")\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.legend()\n",
    "  \n",
    "plot_loss(history, \"Binary Crossentropy\", 0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5aa0e142",
   "metadata": {},
   "source": [
    "# Plot accuracy\n",
    "\n",
    "def plot_accuracy(history, label, n):\n",
    "  \n",
    "  plt.plot(history.epoch, history.history['accuracy'],\n",
    "               color=colors[n], label='Train ' + label)\n",
    "  \n",
    "  plt.plot(history.epoch, history.history['val_accuracy'],\n",
    "               color=colors[n], label='Val ' + label,\n",
    "               linestyle=\"--\")\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.legend()\n",
    "\n",
    "plot_accuracy(history, \"Accuracy\", 0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2fb407a2",
   "metadata": {},
   "source": [
    "print(history.history.keys())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a10a04d1",
   "metadata": {},
   "source": [
    "def plot_metrics(history):\n",
    "  metrics = ['f1_m', 'loss', 'precision_m', 'recall_m']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()\n",
    "    \n",
    "plot_metrics(history)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "60f581bf",
   "metadata": {},
   "source": [
    "train_predictions_baseline = model.predict(train_ds, batch_size=batch_size)\n",
    "valid_predictions_baseline = model.predict(valid_ds, batch_size=batch_size)\n",
    "\n",
    "def plot_cm(labels, predictions, threshold=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > threshold)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(threshold))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('(True Negatives): ', cm[0][0])\n",
    "  print('(False Positives): ', cm[0][1])\n",
    "  print('(False Negatives): ', cm[1][0])\n",
    "  print('(True Positives): ', cm[1][1])\n",
    "  print('Total: ', np.sum(cm[1]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9b3d3d86",
   "metadata": {},
   "source": [
    "train_pred_bool = np.argmax(train_predictions_baseline, axis=1)\n",
    "\n",
    "print(classification_report(train_labels, train_pred_bool))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "68e338a3",
   "metadata": {},
   "source": [
    "valid_y_pred_bool = np.argmax(valid_predictions_baseline, axis=1)\n",
    "\n",
    "print(classification_report(valid_labels, valid_y_pred_bool))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "82e26ed8",
   "metadata": {},
   "source": [
    "plot_cm(train_labels, train_predictions_baseline)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "99790254",
   "metadata": {},
   "source": [
    "plot_cm(valid_labels, valid_predictions_baseline)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2408bff1",
   "metadata": {},
   "source": [
    "plot_cm(valid_labels, valid_predictions_baseline, threshold=0.1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6252a843",
   "metadata": {},
   "source": [
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "  fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n",
    "\n",
    "  plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n",
    "  plt.xlabel('False positives [%]')\n",
    "  plt.ylabel('True positives [%]')\n",
    "  plt.xlim([-1.5,101.5])\n",
    "  plt.ylim([0,101.5])\n",
    "  plt.grid(True)\n",
    "  ax = plt.gca()\n",
    "  ax.set_aspect('equal')\n",
    "  \n",
    "plot_roc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\n",
    "plot_roc(\"Test Baseline\", valid_labels, valid_predictions_baseline, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower right');"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cd43da36",
   "metadata": {},
   "source": [
    "def plot_prc(name, labels, predictions, **kwargs):\n",
    "    precision, recall, _ = sklearn.metrics.precision_recall_curve(labels, predictions)\n",
    "\n",
    "    plt.plot(precision, recall, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('Precision')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "plot_prc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\n",
    "plot_prc(\"Test Baseline\", valid_labels, valid_predictions_baseline, color=colors[0], linestyle='--')\n",
    "plt.legend(loc='lower left');"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3dd8783e",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "test_hdf5 = h5py.File(f\"{ROOT_DIR}/test-image.hdf5\", 'r')\n",
    "test_df = pd.read_csv(f\"{ROOT_DIR}/test-metadata.csv\")\n",
    "test_ids = test_df.isic_id.values\n",
    "print(test_df)\n",
    "\n",
    "test_images = [None]*len(test_ids)\n",
    "test_labels = [None]*len(test_ids)\n",
    "\n",
    "for i, isic_id in enumerate(test_ids):\n",
    "    if isic_id in test_hdf5:\n",
    "        if test_hdf5[isic_id][()] is not None:\n",
    "            test_images[i] = test_hdf5[isic_id][()]\n",
    "            test_labels[i] = test_df[isic_id].target\n",
    "\n",
    "print(f\"Loaded {len(images)} images.\")\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_images, test_labels)\n",
    "\n",
    "test_dataset = test_dataset.cache()\n",
    "\n",
    "test_dataset = test_dataset.map(image_decoder, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "test_dataset = test_dataset.batch(batch_size=batch_size, drop_remainder=True)\n",
    "\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(f\"Testing dataset size: {test_dataset.cardinality().numpy()}\")\n",
    "\n",
    "predictions = model.predict(test_dataset)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9cc53dd86cba149e",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "image_ids = []\n",
    "predictions = []\n",
    "\n",
    "with h5py.File(\"I/SIC2024_SkinCancerDetection/data/test-image.hdf5\", 'r') as hdf:\n",
    "    for key in hdf.keys():\n",
    "        dataset = hdf[key]\n",
    "        if isinstance(dataset, h5py.Dataset):\n",
    "            \n",
    "            img_data = dataset[()]\n",
    "            img_data = np.frombuffer(img_data, dtype=np.uint8)\n",
    "            img = Image.open(io.BytesIO(img_data))\n",
    "\n",
    "            img = test_transform(img)\n",
    "\n",
    "            img = img.unsqueeze(0).to(CONFIG['device']) \n",
    "\n",
    "            output = model(img)\n",
    "            # probability = output.squeeze().cpu().item()\n",
    "\n",
    "            image_ids.append(key)\n",
    "            predictions.append(output)\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'isic_id': image_ids,\n",
    "    'target': predictions \n",
    "})\n",
    "\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "feca4cc3f5ea2bb6",
   "metadata": {},
   "source": [
    "# TODO: Custom training loop with evaluation"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
